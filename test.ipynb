{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e9b15b5",
   "metadata": {},
   "source": [
    "# `test.ipynb` - Model Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8c1bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from operator import add\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
    "\n",
    "# Custom imports\n",
    "from model import build_unet\n",
    "from utils import create_dir, seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4a09d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:13<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating Images...\n",
      "\n",
      "Final Results:\n",
      "Dice: 0.7725 | IoU: 0.6330 | Acc: 0.9622\n",
      "Speed: 185.89 FPS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def save_image_comparison(image, mask, pred, dice, iou, save_path):\n",
    "    \"\"\" Visualization Function that creates a side-by-side comparison: Original | Truth | U-Net Prediction \"\"\"\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    ax[0].imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    ax[0].set_title(\"Original Image\")\n",
    "    ax[0].axis(\"off\")\n",
    "    \n",
    "    ax[1].imshow(mask, cmap=\"gray\")\n",
    "    ax[1].set_title(\"Ground Truth (Doctor)\")\n",
    "    ax[1].axis(\"off\")\n",
    "    \n",
    "    ax[2].imshow(pred, cmap=\"gray\")\n",
    "    ax[2].set_title(f\"U-Net Result\\nDice: {dice:.2f} | IoU: {iou:.2f}\")\n",
    "    ax[2].axis(\"off\")\n",
    "    \n",
    "    plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\" Calculates all scores for one image \"\"\"\n",
    "    y_true = (y_true.cpu().numpy() > 0.5).astype(np.uint8).flatten()\n",
    "    y_pred = (y_pred.cpu().numpy() > 0.5).astype(np.uint8).flatten()\n",
    "\n",
    "    return [\n",
    "        jaccard_score(y_true, y_pred),\n",
    "        f1_score(y_true, y_pred),\n",
    "        recall_score(y_true, y_pred),\n",
    "        precision_score(y_true, y_pred),\n",
    "        accuracy_score(y_true, y_pred)\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    seeding(42)\n",
    "    create_dir(\"results\")\n",
    "    \n",
    "    test_x = sorted(glob(\"new_data/test/image/*\"))\n",
    "    test_y = sorted(glob(\"new_data/test/mask/*\"))\n",
    "\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = build_unet().to(device)\n",
    "    model.load_state_dict(torch.load(\"files/checkpoint.pth\", map_location=device))\n",
    "    model.eval()\n",
    "\n",
    "    metrics_score = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "    time_taken = []\n",
    "\n",
    "    for i, (x_path, y_path) in tqdm(enumerate(zip(test_x, test_y)), total=len(test_x)):\n",
    "        name = os.path.basename(x_path).split(\".\")[0]\n",
    "        \n",
    "        # Image Processing\n",
    "        image = cv2.imread(x_path, cv2.IMREAD_COLOR)\n",
    "        x = np.transpose(image, (2, 0, 1)) / 255.0\n",
    "        x = torch.from_numpy(np.expand_dims(x, axis=0)).float().to(device)\n",
    "        \n",
    "        # Mask Processing\n",
    "        mask = cv2.imread(y_path, cv2.IMREAD_GRAYSCALE)\n",
    "        y = (mask / 255.0)\n",
    "        y_tensor = torch.from_numpy(np.expand_dims(np.expand_dims(y, 0), 0)).float().to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            start_time = time.time()\n",
    "            y_pred = torch.sigmoid(model(x))\n",
    "            time_taken.append(time.time() - start_time)\n",
    "            \n",
    "            # Calculate scores for this specific image\n",
    "            score = calculate_metrics(y_tensor, y_pred)\n",
    "            metrics_score = list(map(add, metrics_score, score))\n",
    "            \n",
    "            # Post-process mask for visualization\n",
    "            pred_y_final = (y_pred[0].cpu().numpy().squeeze() > 0.5).astype(np.uint8)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Finally We Save Every Comparison Image\n",
    "        save_image_comparison(image, mask, pred_y_final * 255, score[1], score[0], f\"results/comp_{name}.png\")\n",
    "\n",
    "\n",
    "    print(\"\\nGenerating Images...\")\n",
    "\n",
    "    # Final Print\n",
    "    avg = [s / len(test_x) for s in metrics_score]\n",
    "    print(f\"\\nFinal Results:\\nDice: {avg[1]:.4f} | IoU: {avg[0]:.4f} | Acc: {avg[4]:.4f}\")\n",
    "    print(f\"Speed: {1/np.mean(time_taken):.2f} FPS\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_unet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
